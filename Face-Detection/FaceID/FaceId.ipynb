{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.mkdir(\"faceid_train\")\n",
    "os.mkdir(\"faceid_val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_list=[\"http://vap.aau.dk/wp-content/uploads/VAPRBGD/(2012-05-16)(151751).zip\", \"http://vap.aau.dk/wp-content/uploads/VAPRBGD/(2012-05-16)(153054).zip\", \"http://vap.aau.dk/wp-content/uploads/VAPRBGD/(2012-05-16)(154211).zip\", \"http://vap.aau.dk/wp-content/uploads/VAPRBGD/(2012-05-16)(160440).zip\", \"http://vap.aau.dk/wp-content/uploads/VAPRBGD/(2012-05-16)(160931).zip\", \"http://vap.aau.dk/wp-content/uploads/VAPRBGD/(2012-05-16)(161342).zip\", \"http://vap.aau.dk/wp-content/uploads/VAPRBGD/(2012-05-16)(163349).zip\", \"http://vap.aau.dk/wp-content/uploads/VAPRBGD/(2012-05-16)(164248).zip\", \"http://vap.aau.dk/wp-content/uploads/VAPRBGD/(2012-05-17)(141550).zip\", \\\n",
    "          \"http://vap.aau.dk/wp-content/uploads/VAPRBGD/(2012-05-17)(142154).zip\", \"http://vap.aau.dk/wp-content/uploads/VAPRBGD/(2012-05-17)(142457).zip\", \"http://vap.aau.dk/wp-content/uploads/VAPRBGD/(2012-05-17)(143016).zip\", \"http://vap.aau.dk/wp-content/uploads/VAPRBGD/(2012-05-18)(132824).zip\", \"http://vap.aau.dk/wp-content/uploads/VAPRBGD/(2012-05-18)(133201).zip\", \"http://vap.aau.dk/wp-content/uploads/VAPRBGD/(2012-05-18)(133846).zip\", \\\n",
    "          \"http://vap.aau.dk/wp-content/uploads/VAPRBGD/(2012-05-18)(134239).zip\", \"http://vap.aau.dk/wp-content/uploads/VAPRBGD/(2012-05-18)(134757).zip\", \"http://vap.aau.dk/wp-content/uploads/VAPRBGD/(2012-05-18)(140516).zip\", \"http://vap.aau.dk/wp-content/uploads/VAPRBGD/(2012-05-18)(143345).zip\", \"http://vap.aau.dk/wp-content/uploads/VAPRBGD/(2012-05-18)(144316).zip\", \"http://vap.aau.dk/wp-content/uploads/VAPRBGD/(2012-05-18)(145150).zip\", \"http://vap.aau.dk/wp-content/uploads/VAPRBGD/(2012-05-18)(145623).zip\", \"http://vap.aau.dk/wp-content/uploads/VAPRBGD/(2012-05-18)(150303).zip\", \\\n",
    "          \"http://vap.aau.dk/wp-content/uploads/VAPRBGD/(2012-05-18)(150650).zip\", \"http://vap.aau.dk/wp-content/uploads/VAPRBGD/(2012-05-18)(151337).zip\", \"http://vap.aau.dk/wp-content/uploads/VAPRBGD/(2012-05-18)(151650).zip\"]\n",
    "val_list=[\"http://vap.aau.dk/wp-content/uploads/VAPRBGD/(2012-05-18)(152717).zip\", \"http://vap.aau.dk/wp-content/uploads/VAPRBGD/(2012-05-18)(153532).zip\", \"http://vap.aau.dk/wp-content/uploads/VAPRBGD/(2012-05-18)(154129).zip\", \"http://vap.aau.dk/wp-content/uploads/VAPRBGD/(2012-05-18)(154728).zip\", \"http://vap.aau.dk/wp-content/uploads/VAPRBGD/(2012-05-18)(155357).zip\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, zipfile, io\n",
    "for link in link_list:\n",
    "    r = requests.get(link, stream=True)\n",
    "    z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "    z.extractall(\"faceid_train\")\n",
    "for link in val_list:\n",
    "    r = requests.get(link, stream=True)\n",
    "    z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "    z.extractall(\"faceid_val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faceid_train/(2012-05-16)(160931)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-ed12bfa6c86f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmat_small\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmat2_small\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcreate_couple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"faceid_train/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-ed12bfa6c86f>\u001b[0m in \u001b[0;36mcreate_couple\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mval\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1200\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m1200\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m                 \u001b[0mmat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0mj\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: ''"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "def create_couple(file_path):\n",
    "    folder=np.random.choice(glob.glob(file_path + \"*\"))\n",
    "    while folder == \"datalab\":\n",
    "      folder=np.random.choice(glob.glob(file_path + \"*\"))\n",
    "    print(folder)\n",
    "    mat=np.zeros((480,640), dtype='float32')\n",
    "    i=0\n",
    "    j=0\n",
    "    depth_file = np.random.choice(glob.glob(folder + \"/*.dat\"))\n",
    "    with open(depth_file) as file:\n",
    "        for line in file:\n",
    "            vals = line.split('\\t')\n",
    "            for val in vals:\n",
    "                if val == \"\\n\": continue\n",
    "                if int(val) > 1200 or int(val) == -1: val= 1200\n",
    "                mat[i][j]=float(int(val))\n",
    "                j+=1\n",
    "                j=j%640\n",
    "\n",
    "            i+=1\n",
    "        mat = np.asarray(mat)\n",
    "    mat_small=mat[140:340,220:420]\n",
    "    mat_small=(mat_small-np.mean(mat_small))/np.max(mat_small)\n",
    "    plt.imshow(mat_small)\n",
    "    plt.show()\n",
    "\n",
    "    mat2=np.zeros((480,640), dtype='float32')\n",
    "    i=0\n",
    "    j=0\n",
    "    depth_file = np.random.choice(glob.glob(folder + \"/*.dat\"))\n",
    "    with open(depth_file) as file:\n",
    "        for line in file:\n",
    "            vals = line.split('\\t')\n",
    "            for val in vals:\n",
    "                if val == \"\\n\": continue\n",
    "                if int(val) > 1200 or int(val) == -1: val= 1200\n",
    "                mat2[i][j]=float(int(val))\n",
    "                j+=1\n",
    "                j=j%640\n",
    "\n",
    "            i+=1\n",
    "        mat2 = np.asarray(mat2)\n",
    "    mat2_small=mat2[140:340,220:420]\n",
    "    mat2_small=(mat2_small-np.mean(mat2_small))/np.max(mat2_small)\n",
    "    plt.imshow(mat2_small)\n",
    "    plt.show()\n",
    "    return np.array([mat_small, mat2_small])\n",
    "\n",
    "print(create_couple(\"faceid_train/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-e00c4601971a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfull1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m \u001b[0mcreate_couple_rgbd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"faceid_val/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-e00c4601971a>\u001b[0m in \u001b[0;36mcreate_couple_rgbd\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mval\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1200\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m1200\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0mmat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                 \u001b[0mj\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: ''"
     ]
    }
   ],
   "source": [
    "def create_couple_rgbd(file_path):\n",
    "    folder=np.random.choice(glob.glob(file_path + \"*\"))\n",
    "    while folder == \"datalab\":\n",
    "      folder=np.random.choice(glob.glob(file_path + \"*\"))\n",
    "  #  print(folder)\n",
    "    mat=np.zeros((480,640), dtype='float32')\n",
    "    i=0\n",
    "    j=0\n",
    "    depth_file = np.random.choice(glob.glob(folder + \"/*.dat\"))\n",
    "    with open(depth_file) as file:\n",
    "        for line in file:\n",
    "            vals = line.split('\\t')\n",
    "            for val in vals:\n",
    "                if val == \"\\n\": continue    \n",
    "                if int(val) > 1200 or int(val) == -1: val= 1200\n",
    "                mat[i][j]=float(int(val))\n",
    "                j+=1\n",
    "                j=j%640\n",
    "\n",
    "            i+=1\n",
    "        mat = np.asarray(mat)\n",
    "    mat_small=mat[140:340,220:420]\n",
    "    img = Image.open(depth_file[:-5] + \"c.bmp\")\n",
    "    img.thumbnail((640,480))\n",
    "    img = np.asarray(img)\n",
    "    img = img[140:340,220:420]\n",
    "    mat_small=(mat_small-np.mean(mat_small))/np.max(mat_small)\n",
    "#    plt.imshow(mat_small)\n",
    "#    plt.show()\n",
    "#    plt.imshow(img)\n",
    "#    plt.show()\n",
    "    \n",
    "    \n",
    "    mat2=np.zeros((480,640), dtype='float32')\n",
    "    i=0\n",
    "    j=0\n",
    "    depth_file = np.random.choice(glob.glob(folder + \"/*.dat\"))\n",
    "    with open(depth_file) as file:\n",
    "        for line in file:\n",
    "            vals = line.split('\\t')\n",
    "            for val in vals:\n",
    "                if val == \"\\n\": continue\n",
    "                if int(val) > 1200 or int(val) == -1: val= 1200\n",
    "                mat2[i][j]=float(int(val))\n",
    "                j+=1\n",
    "                j=j%640\n",
    "\n",
    "            i+=1\n",
    "        mat2 = np.asarray(mat2)\n",
    "    mat2_small=mat2[140:340,220:420]\n",
    "    img2 = Image.open(depth_file[:-5] + \"c.bmp\")\n",
    "    img2.thumbnail((640,480))\n",
    "    img2 = np.asarray(img2)\n",
    "    img2 = img2[160:360,240:440]\n",
    "\n",
    " #   plt.imshow(img2)\n",
    " #   plt.show()\n",
    "    mat2_small=(mat2_small-np.mean(mat2_small))/np.max(mat2_small)\n",
    " #   plt.imshow(mat2_small)\n",
    " #   plt.show()\n",
    "    \n",
    "    full1 = np.zeros((200,200,4))\n",
    "    full1[:,:,:3] = img[:,:,:3]\n",
    "    full1[:,:,3] = mat_small\n",
    "    \n",
    "    full2 = np.zeros((200,200,4))\n",
    "    full2[:,:,:3] = img2[:,:,:3]\n",
    "    full2[:,:,3] = mat2_small\n",
    "    return np.array([full1, full2])\n",
    "\n",
    "create_couple_rgbd(\"faceid_val/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-ddf3dc230601>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmat_small\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmat2_small\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m \u001b[0mcreate_wrong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"faceid_train/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-ddf3dc230601>\u001b[0m in \u001b[0;36mcreate_wrong\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mval\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1200\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m1200\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m                 \u001b[0mmat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                 \u001b[0mj\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: ''"
     ]
    }
   ],
   "source": [
    "def create_wrong(file_path):\n",
    "    folder=np.random.choice(glob.glob(file_path + \"*\"))\n",
    "    while folder == \"datalab\":\n",
    "      folder=np.random.choice(glob.glob(file_path + \"*\"))    \n",
    "    mat=np.zeros((480,640), dtype='float32')\n",
    "    i=0\n",
    "    j=0\n",
    "    depth_file = np.random.choice(glob.glob(folder + \"/*.dat\"))\n",
    "    with open(depth_file) as file:\n",
    "        for line in file:\n",
    "            vals = line.split('\\t')\n",
    "            for val in vals:\n",
    "                if val == \"\\n\": continue \n",
    "                if int(val) > 1200 or int(val) == -1: val= 1200\n",
    "                mat[i][j]=float(int(val))\n",
    "                j+=1\n",
    "                j=j%640\n",
    "\n",
    "            i+=1\n",
    "        mat = np.asarray(mat)\n",
    "    mat_small=mat[140:340,220:420]\n",
    "    mat_small=(mat_small-np.mean(mat_small))/np.max(mat_small)\n",
    " #   plt.imshow(mat_small)\n",
    " #   plt.show()\n",
    "    \n",
    "    folder2=np.random.choice(glob.glob(file_path + \"*\"))\n",
    "    while folder==folder2 or folder2==\"datalab\": #it activates if it chose the same folder\n",
    "        folder2=np.random.choice(glob.glob(file_path + \"*\"))\n",
    "    mat2=np.zeros((480,640), dtype='float32')\n",
    "    i=0\n",
    "    j=0\n",
    "    depth_file = np.random.choice(glob.glob(folder2 + \"/*.dat\"))\n",
    "    with open(depth_file) as file:\n",
    "        for line in file:\n",
    "            vals = line.split('\\t')\n",
    "            for val in vals:\n",
    "                if val == \"\\n\": continue\n",
    "                if int(val) > 1200 or int(val) == -1: val= 1200\n",
    "                mat2[i][j]=float(int(val))\n",
    "                j+=1\n",
    "                j=j%640\n",
    "\n",
    "            i+=1\n",
    "        mat2 = np.asarray(mat2)\n",
    "    mat2_small=mat2[140:340,220:420]\n",
    "    mat2_small=(mat2_small-np.mean(mat2_small))/np.max(mat2_small)\n",
    " #   plt.imshow(mat2_small)\n",
    " #   plt.show()\n",
    "  \n",
    "    \n",
    "    return np.array([mat_small, mat2_small])\n",
    "\n",
    "create_wrong(\"faceid_train/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-9b3910379206>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfull1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m \u001b[0mcreate_wrong_rgbd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"faceid_val/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-9b3910379206>\u001b[0m in \u001b[0;36mcreate_wrong_rgbd\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mval\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1200\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m1200\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m                 \u001b[0mmat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                 \u001b[0mj\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: ''"
     ]
    }
   ],
   "source": [
    "def create_wrong_rgbd(file_path):\n",
    "    folder=np.random.choice(glob.glob(file_path + \"*\"))\n",
    "    while folder == \"datalab\":\n",
    "      folder=np.random.choice(glob.glob(file_path + \"*\"))    \n",
    "    mat=np.zeros((480,640), dtype='float32')\n",
    "    i=0\n",
    "    j=0\n",
    "    depth_file = np.random.choice(glob.glob(folder + \"/*.dat\"))\n",
    "    with open(depth_file) as file:\n",
    "        for line in file:\n",
    "            vals = line.split('\\t')\n",
    "            for val in vals:\n",
    "                if val == \"\\n\": continue\n",
    "                if int(val) > 1200 or int(val) == -1: val= 1200\n",
    "                mat[i][j]=float(int(val))\n",
    "                j+=1\n",
    "                j=j%640\n",
    "\n",
    "            i+=1\n",
    "        mat = np.asarray(mat)\n",
    "    mat_small=mat[140:340,220:420]\n",
    "    img = Image.open(depth_file[:-5] + \"c.bmp\")\n",
    "    img.thumbnail((640,480))\n",
    "    img = np.asarray(img)\n",
    "    img = img[140:340,220:420]\n",
    "    mat_small=(mat_small-np.mean(mat_small))/np.max(mat_small)\n",
    "  #  plt.imshow(img)\n",
    "  #  plt.show()\n",
    "  #  plt.imshow(mat_small)\n",
    "  #  plt.show()\n",
    "    folder2=np.random.choice(glob.glob(file_path + \"*\"))\n",
    "    while folder==folder2 or folder2==\"datalab\": #it activates if it chose the same folder\n",
    "        folder2=np.random.choice(glob.glob(file_path + \"*\"))\n",
    "    mat2=np.zeros((480,640), dtype='float32')\n",
    "    i=0\n",
    "    j=0\n",
    "    depth_file = np.random.choice(glob.glob(folder2 + \"/*.dat\"))\n",
    "    with open(depth_file) as file:\n",
    "        for line in file:\n",
    "            vals = line.split('\\t')\n",
    "            for val in vals:\n",
    "                if val == \"\\n\": continue \n",
    "                if int(val) > 1200 or int(val) == -1: val= 1200\n",
    "                mat2[i][j]=float(int(val))\n",
    "                j+=1\n",
    "                j=j%640\n",
    "\n",
    "            i+=1\n",
    "        mat2 = np.asarray(mat2)\n",
    "    mat2_small=mat2[140:340,220:420]\n",
    "    img2 = Image.open(depth_file[:-5] + \"c.bmp\")\n",
    "    img2.thumbnail((640,480))\n",
    "    img2 = np.asarray(img2)\n",
    "    img2 = img2[140:340,220:420]\n",
    "    mat2_small=(mat2_small-np.mean(mat2_small))/np.max(mat2_small)\n",
    " #   plt.imshow(img2)\n",
    " #   plt.show()\n",
    " #   plt.imshow(mat2_small)\n",
    " #   plt.show()\n",
    "    full1 = np.zeros((200,200,4))\n",
    "    full1[:,:,:3] = img[:,:,:3]\n",
    "    full1[:,:,3] = mat_small\n",
    "    \n",
    "    full2 = np.zeros((200,200,4))\n",
    "    full2[:,:,:3] = img2[:,:,:3]\n",
    "    full2[:,:,3] = mat2_small\n",
    "    return np.array([full1, full2])\n",
    "\n",
    "create_wrong_rgbd(\"faceid_val/\")[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 200, 200, 4)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)                (None, 98, 98, 64)    6464        input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNorm (None, 98, 98, 64)    256         conv2d_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 98, 98, 64)    0           batch_normalization_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)   (None, 48, 48, 64)    0           activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)                (None, 48, 48, 16)    1040        max_pooling2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 48, 48, 16)    0           conv2d_2[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)                (None, 48, 48, 16)    272         activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)                (None, 48, 48, 16)    2320        activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, 48, 48, 16)    0           conv2d_3[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)        (None, 48, 48, 16)    0           conv2d_4[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)      (None, 48, 48, 32)    0           activation_3[0][0]               \n",
      "                                                                   activation_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)                (None, 48, 48, 16)    528         concatenate_1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_5 (Activation)        (None, 48, 48, 16)    0           conv2d_5[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)                (None, 48, 48, 16)    272         activation_5[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)                (None, 48, 48, 16)    2320        activation_5[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_6 (Activation)        (None, 48, 48, 16)    0           conv2d_6[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_7 (Activation)        (None, 48, 48, 16)    0           conv2d_7[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)      (None, 48, 48, 32)    0           activation_6[0][0]               \n",
      "                                                                   activation_7[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)   (None, 23, 23, 32)    0           concatenate_2[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)                (None, 23, 23, 32)    1056        max_pooling2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "activation_8 (Activation)        (None, 23, 23, 32)    0           conv2d_8[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)                (None, 23, 23, 32)    1056        activation_8[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)               (None, 23, 23, 32)    9248        activation_8[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_9 (Activation)        (None, 23, 23, 32)    0           conv2d_9[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_10 (Activation)       (None, 23, 23, 32)    0           conv2d_10[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)      (None, 23, 23, 64)    0           activation_9[0][0]               \n",
      "                                                                   activation_10[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)               (None, 23, 23, 32)    2080        concatenate_3[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_11 (Activation)       (None, 23, 23, 32)    0           conv2d_11[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)               (None, 23, 23, 32)    1056        activation_11[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)               (None, 23, 23, 32)    9248        activation_11[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_12 (Activation)       (None, 23, 23, 32)    0           conv2d_12[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_13 (Activation)       (None, 23, 23, 32)    0           conv2d_13[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)      (None, 23, 23, 64)    0           activation_12[0][0]              \n",
      "                                                                   activation_13[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)   (None, 11, 11, 64)    0           concatenate_4[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)               (None, 11, 11, 48)    3120        max_pooling2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "activation_14 (Activation)       (None, 11, 11, 48)    0           conv2d_14[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)               (None, 11, 11, 48)    2352        activation_14[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)               (None, 11, 11, 48)    20784       activation_14[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_15 (Activation)       (None, 11, 11, 48)    0           conv2d_15[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_16 (Activation)       (None, 11, 11, 48)    0           conv2d_16[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)      (None, 11, 11, 96)    0           activation_15[0][0]              \n",
      "                                                                   activation_16[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)               (None, 11, 11, 48)    4656        concatenate_5[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_17 (Activation)       (None, 11, 11, 48)    0           conv2d_17[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)               (None, 11, 11, 48)    2352        activation_17[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)               (None, 11, 11, 48)    20784       activation_17[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_18 (Activation)       (None, 11, 11, 48)    0           conv2d_18[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_19 (Activation)       (None, 11, 11, 48)    0           conv2d_19[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)      (None, 11, 11, 96)    0           activation_18[0][0]              \n",
      "                                                                   activation_19[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)               (None, 11, 11, 64)    6208        concatenate_6[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_20 (Activation)       (None, 11, 11, 64)    0           conv2d_20[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)               (None, 11, 11, 64)    4160        activation_20[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)               (None, 11, 11, 64)    36928       activation_20[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_21 (Activation)       (None, 11, 11, 64)    0           conv2d_21[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_22 (Activation)       (None, 11, 11, 64)    0           conv2d_22[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)      (None, 11, 11, 128)   0           activation_21[0][0]              \n",
      "                                                                   activation_22[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)               (None, 11, 11, 64)    8256        concatenate_7[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_23 (Activation)       (None, 11, 11, 64)    0           conv2d_23[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)               (None, 11, 11, 64)    4160        activation_23[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)               (None, 11, 11, 64)    36928       activation_23[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_24 (Activation)       (None, 11, 11, 64)    0           conv2d_24[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_25 (Activation)       (None, 11, 11, 64)    0           conv2d_25[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)      (None, 11, 11, 128)   0           activation_24[0][0]              \n",
      "                                                                   activation_25[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 11, 11, 128)   0           concatenate_8[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)               (None, 11, 11, 512)   66048       dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_26 (Activation)       (None, 11, 11, 512)   0           conv2d_26[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 253,952\n",
      "Trainable params: 253,824\n",
      "Non-trainable params: 128\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:1205: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:2901: calling l2_normalize (from tensorflow.python.ops.nn_impl) with dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "dim is deprecated, use axis instead\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 200, 200, 4)       0         \n",
      "_________________________________________________________________\n",
      "model_1 (Model)              (None, 11, 11, 512)       253952    \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 61952)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               31719936  \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None, 128)               0         \n",
      "=================================================================\n",
      "Total params: 32,039,552\n",
      "Trainable params: 32,039,424\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:1188: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_3 (InputLayer)             (None, 200, 200, 4)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_4 (InputLayer)             (None, 200, 200, 4)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "model_2 (Model)                  (None, 128)           32039552    input_3[0][0]                    \n",
      "                                                                   input_4[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)                (None, 1)             0           model_2[1][0]                    \n",
      "                                                                   model_2[2][0]                    \n",
      "====================================================================================================\n",
      "Total params: 32,039,552\n",
      "Trainable params: 32,039,424\n",
      "Non-trainable params: 128\n",
      "____________________________________________________________________________________________________\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:1290: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-4:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python2.7/threading.py\", line 801, in __bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/lib/python2.7/threading.py\", line 754, in run\n",
      "    self.__target(*self.__args, **self.__kwargs)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/keras/utils/data_utils.py\", line 568, in data_generator_task\n",
      "    generator_output = next(self._generator)\n",
      "  File \"<ipython-input-10-c879d3a7ff40>\", line 146, in generator\n",
      "    X.append(create_couple_rgbd(\"faceid_train/\").reshape((2,200,200,4)))\n",
      "  File \"<ipython-input-7-e00c4601971a>\", line 15, in create_couple_rgbd\n",
      "    if int(val) > 1200 or int(val) == -1: val= 1200\n",
      "ValueError: invalid literal for int() with base 10: ''\n",
      "\n"
     ]
    },
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-c879d3a7ff40>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0mval_gen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_final\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\"\"\"# Some model tests.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/legacy/interfaces.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2009\u001b[0m                 \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2010\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2011\u001b[0;31m                     \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2013\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"# Network crafting.\n",
    "Now we create the network. We first manually create the *constrative loss*, then we define the network architecture starting from the SqueezeNet architecture, and then using it as a siamese-network for embedding faces into a manifold. (the network for now is very big and could be heavily optimized, but I just wanted to show a proof-of-concept)\n",
    "\"\"\"\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, Lambda, ELU, concatenate, GlobalAveragePooling2D, Input, BatchNormalization, SeparableConv2D, Subtract, concatenate\n",
    "from keras.activations import relu, softmax\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D, AveragePooling2D\n",
    "from keras.optimizers import Adam, RMSprop, SGD\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "\n",
    "def euclidean_distance(inputs):\n",
    "    assert len(inputs) == 2, \\\n",
    "        'Euclidean distance needs 2 inputs, %d given' % len(inputs)\n",
    "    u, v = inputs\n",
    "    return K.sqrt(K.sum((K.square(u - v)), axis=1, keepdims=True))\n",
    "        \n",
    "\n",
    "def contrastive_loss(y_true,y_pred):\n",
    "    margin=1.\n",
    "    return K.mean((1. - y_true) * K.square(y_pred) + y_true * K.square(K.maximum(margin - y_pred, 0.)))\n",
    "   # return K.mean( K.square(y_pred) )\n",
    "\n",
    "def fire(x, squeeze=16, expand=64):\n",
    "    x = Convolution2D(squeeze, (1,1), padding='valid')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    left = Convolution2D(expand, (1,1), padding='valid')(x)\n",
    "    left = Activation('relu')(left)\n",
    "    \n",
    "    right = Convolution2D(expand, (3,3), padding='same')(x)\n",
    "    right = Activation('relu')(right)\n",
    "    \n",
    "    x = concatenate([left, right], axis=3)\n",
    "    return x\n",
    "\n",
    "img_input=Input(shape=(200,200,4))\n",
    "\n",
    "x = Convolution2D(64, (5, 5), strides=(2, 2), padding='valid')(img_input)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2))(x)\n",
    "\n",
    "x = fire(x, squeeze=16, expand=16)\n",
    "\n",
    "x = fire(x, squeeze=16, expand=16)\n",
    "\n",
    "x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2))(x)\n",
    "\n",
    "\n",
    "x = fire(x, squeeze=32, expand=32)\n",
    "\n",
    "x = fire(x, squeeze=32, expand=32)\n",
    "\n",
    "x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2))(x)\n",
    "\n",
    "\n",
    "x = fire(x, squeeze=48, expand=48)\n",
    "\n",
    "x = fire(x, squeeze=48, expand=48)\n",
    "\n",
    "x = fire(x, squeeze=64, expand=64)\n",
    "\n",
    "x = fire(x, squeeze=64, expand=64)\n",
    "\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "x = Convolution2D(512, (1, 1), padding='same')(x)\n",
    "out = Activation('relu')(x)\n",
    "\n",
    "\n",
    "modelsqueeze= Model(img_input, out)\n",
    "\n",
    "modelsqueeze.summary()\n",
    "\n",
    "im_in = Input(shape=(200,200,4))\n",
    "#wrong = Input(shape=(200,200,3))\n",
    "\n",
    "x1 = modelsqueeze(im_in)\n",
    "#x = Convolution2D(64, (5, 5), padding='valid', strides =(2,2))(x)\n",
    "\n",
    "#x1 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2))(x1)\n",
    "\n",
    "\"\"\"\n",
    "x1 = Convolution2D(256, (3,3), padding='valid', activation=\"relu\")(x1)\n",
    "x1 = Dropout(0.4)(x1)\n",
    "x1 = MaxPooling2D(pool_size=(3, 3), strides=(1, 1))(x1)\n",
    "x1 = Convolution2D(256, (3,3), padding='valid', activation=\"relu\")(x1)\n",
    "x1 = BatchNormalization()(x1)\n",
    "x1 = Dropout(0.4)(x1)\n",
    "x1 = Convolution2D(64, (1,1), padding='same', activation=\"relu\")(x1)\n",
    "x1 = BatchNormalization()(x1)\n",
    "x1 = Dropout(0.4)(x1)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "x1 = Flatten()(x1)\n",
    "\n",
    "x1 = Dense(512, activation=\"relu\")(x1)\n",
    "x1 = Dropout(0.2)(x1)\n",
    "#x1 = BatchNormalization()(x1)\n",
    "feat_x = Dense(128, activation=\"linear\")(x1)\n",
    "feat_x = Lambda(lambda  x: K.l2_normalize(x,axis=1))(feat_x)\n",
    "\n",
    "\n",
    "model_top = Model(inputs = [im_in], outputs = feat_x)\n",
    "\n",
    "model_top.summary()\n",
    "\n",
    "im_in1 = Input(shape=(200,200,4))\n",
    "im_in2 = Input(shape=(200,200,4))\n",
    "\n",
    "feat_x1 = model_top(im_in1)\n",
    "feat_x2 = model_top(im_in2)\n",
    "\n",
    "\n",
    "lambda_merge = Lambda(euclidean_distance)([feat_x1, feat_x2])\n",
    "\n",
    "\n",
    "model_final = Model(inputs = [im_in1, im_in2], outputs = lambda_merge)\n",
    "\n",
    "model_final.summary()\n",
    "\n",
    "adam = Adam(lr=0.001)\n",
    "\n",
    "sgd = SGD(lr=0.001, momentum=0.9)\n",
    "\n",
    "model_final.compile(optimizer=adam, loss=contrastive_loss)\n",
    "\n",
    "\"\"\"# Learning phase.\n",
    "We write the generators that will give our model batches of data to train on, then we run the training.\n",
    "\"\"\"\n",
    "\n",
    "def generator(batch_size):\n",
    "  \n",
    "  while 1:\n",
    "    X=[]\n",
    "    y=[]\n",
    "    switch=True\n",
    "    for _ in range(batch_size):\n",
    "   #   switch += 1\n",
    "      if switch:\n",
    "     #   print(\"correct\")\n",
    "        X.append(create_couple_rgbd(\"faceid_train/\").reshape((2,200,200,4)))\n",
    "        y.append(np.array([0.]))\n",
    "      else:\n",
    "     #   print(\"wrong\")\n",
    "        X.append(create_wrong_rgbd(\"faceid_train/\").reshape((2,200,200,4)))\n",
    "        y.append(np.array([1.]))\n",
    "      switch=not switch\n",
    "    X = np.asarray(X)\n",
    "    y = np.asarray(y)\n",
    "    XX1=X[0,:]\n",
    "    XX2=X[1,:]\n",
    "    yield [X[:,0],X[:,1]],y\n",
    "\n",
    "def val_generator(batch_size):\n",
    "  \n",
    "  while 1:\n",
    "    X=[]\n",
    "    y=[]\n",
    "    switch=True\n",
    "    for _ in range(batch_size):\n",
    "      if switch:\n",
    "        X.append(create_couple_rgbd(\"faceid_val/\").reshape((2,200,200,4)))\n",
    "        y.append(np.array([0.]))\n",
    "      else:\n",
    "        X.append(create_wrong_rgbd(\"faceid_val/\").reshape((2,200,200,4)))\n",
    "        y.append(np.array([1.]))\n",
    "      switch=not switch\n",
    "    X = np.asarray(X)\n",
    "    y = np.asarray(y)\n",
    "    XX1=X[0,:]\n",
    "    XX2=X[1,:]\n",
    "    yield [X[:,0],X[:,1]],y\n",
    "\n",
    "gen = generator(16)\n",
    "val_gen = val_generator(4)\n",
    "\n",
    "outputs = model_final.fit_generator(gen, steps_per_epoch=30, epochs=50, validation_data = val_gen, validation_steps=20)\n",
    "\n",
    "\"\"\"# Some model tests.\"\"\"\n",
    "\n",
    "cop = create_couple(\"faceid_val/\")\n",
    "model_final.evaluate([cop[0].reshape((1,200,200,4)), cop[1].reshape((1,200,200,4))], np.array([0.]))\n",
    "\n",
    "cop = create_wrong_rgbd(\"faceid_val/\")\n",
    "model_final.predict([cop[0].reshape((1,200,200,4)), cop[1].reshape((1,200,200,4))])\n",
    "\n",
    "\"\"\"# Saving and loading the model.\n",
    "The next cells show both how to save the model weights and upload them into your Drive, and then how to retrieve those weights from the Drive to load a pre-trained model.\n",
    "\"\"\"\n",
    "\n",
    "model_final.save(\"faceid_big_rgbd_2.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named colab",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-c64215034124>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Install the PyDrive wrapper & import libraries.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# This only needs to be done once in a notebook.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpydrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauth\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGoogleAuth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named colab"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "\n",
    "# Install the PyDrive wrapper & import libraries.\n",
    "# This only needs to be done once in a notebook.\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "\n",
    "# Authenticate and create the PyDrive client.\n",
    "# This only needs to be done once in a notebook.\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)\n",
    "\n",
    "# Create & upload a file.\n",
    "uploaded = drive.CreateFile({'title': 'faceid_big_rgbd.h5'})\n",
    "uploaded.SetContentFile('faceid_big_rgbd.h5')\n",
    "uploaded.Upload()\n",
    "print('Uploaded file with ID {}'.format(uploaded.get('id')))\n",
    "\n",
    "# Install the PyDrive wrapper & import libraries.\n",
    "# This only needs to be done once per notebook.\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "\n",
    "# Authenticate and create the PyDrive client.\n",
    "# This only needs to be done once per notebook.\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)\n",
    "\n",
    "# Download a file based on its file ID.\n",
    "#\n",
    "# A file ID looks like: laggVyWshwcyP6kEI-y_W3P8D26sz\n",
    "file_id = '17Lo_ZxYcKO751iYs4XRyIvVXME8Lyc75'\n",
    "downloaded = drive.CreateFile({'id': file_id})\n",
    "#print('Downloaded content \"{}\"'.format(downloaded.GetContentString()))\n",
    "\n",
    "downloaded.GetContentFile('pesi.h5')\n",
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "model_final.load_weights('pesi.h5')\n",
    "\n",
    "\"\"\"# Raw output.\n",
    "Here we create a model that outputs the embedding of an input face instead of the distance between two embeddings, so we can map those outputs.\n",
    "\"\"\"\n",
    "\n",
    "im_in1 = Input(shape=(200,200,4))\n",
    "#im_in2 = Input(shape=(200,200,4))\n",
    "\n",
    "feat_x1 = model_top(im_in1)\n",
    "#feat_x2 = model_top(im_in2)\n",
    "\n",
    "\n",
    "\n",
    "model_output = Model(inputs = im_in1, outputs = feat_x1)\n",
    "\n",
    "model_output.summary()\n",
    "\n",
    "adam = Adam(lr=0.001)\n",
    "\n",
    "sgd = SGD(lr=0.001, momentum=0.9)\n",
    "\n",
    "model_output.compile(optimizer=adam, loss=contrastive_loss)\n",
    "\n",
    "cop = create_couple_rgbd(\"faceid_val/\")\n",
    "model_output.predict(cop[0].reshape((1,200,200,4)))\n",
    "\n",
    "def create_input_rgbd(file_path):\n",
    "  #  print(folder)\n",
    "    mat=np.zeros((480,640), dtype='float32')\n",
    "    i=0\n",
    "    j=0\n",
    "    depth_file = file_path\n",
    "    with open(depth_file) as file:\n",
    "        for line in file:\n",
    "            vals = line.split('\\t')\n",
    "            for val in vals:\n",
    "                if val == \"\\n\": continue    \n",
    "                if int(val) > 1200 or int(val) == -1: val= 1200\n",
    "                mat[i][j]=float(int(val))\n",
    "                j+=1\n",
    "                j=j%640\n",
    "\n",
    "            i+=1\n",
    "        mat = np.asarray(mat)\n",
    "    mat_small=mat[140:340,220:420]\n",
    "    img = Image.open(depth_file[:-5] + \"c.bmp\")\n",
    "    img.thumbnail((640,480))\n",
    "    img = np.asarray(img)\n",
    "    img = img[140:340,220:420]\n",
    "    mat_small=(mat_small-np.mean(mat_small))/np.max(mat_small)\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.grid(True)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.imshow(mat_small)\n",
    "    plt.show()\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.grid(True)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "    full1 = np.zeros((200,200,4))\n",
    "    full1[:,:,:3] = img[:,:,:3]\n",
    "    full1[:,:,3] = mat_small\n",
    "    \n",
    "    return np.array([full1])\n",
    "\n",
    "\"\"\"# Data visualization.\n",
    "Here we store the embeddings for all the faces in the dataset. Then, using both **t-SNE** and **PCA**, we visualize the embeddings going from 128 to 2 dimensions.\n",
    "\"\"\"\n",
    "\n",
    "outputs=[]\n",
    "n=0\n",
    "for folder in glob.glob('faceid_train/*'):\n",
    "  i=0\n",
    "  for file in glob.glob(folder + '/*.dat'):\n",
    "    i+=1\n",
    "    outputs.append(model_output.predict(create_input_rgbd(file).reshape((1,200,200,4))))\n",
    "  print(i)\n",
    "  n+=1\n",
    "  print(\"Folder \", n, \" of \", len(glob.glob('faceid_train/*')))\n",
    "print(len(outputs))\n",
    "\n",
    "outputs= np.asarray(outputs)\n",
    "outputs = outputs.reshape((-1,128))\n",
    "outputs.shape\n",
    "\n",
    "import sklearn\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "X_embedded = TSNE(2).fit_transform(outputs)\n",
    "X_embedded.shape\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "X_PCA = PCA(3).fit_transform(outputs)\n",
    "print(X_PCA.shape)\n",
    "\n",
    "#X_embedded = TSNE(2).fit_transform(X_PCA)\n",
    "#print(X_embedded.shape)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "color = 0\n",
    "for i in range(len((X_embedded))):\n",
    "  el = X_embedded[i]\n",
    "  if i % 51 == 0 and not i==0:\n",
    "    color+=1\n",
    "    color=color%10\n",
    "  plt.scatter(el[0], el[1], color=\"C\" + str(color))\n",
    "\n",
    "\"\"\"# Distance between two arbitrary RGBD pictures.\"\"\"\n",
    "\n",
    "file1 = ('faceid_train/(2012-05-16)(154211)/015_1_d.dat')\n",
    "inp1 = create_input_rgbd(file1)\n",
    "file1 = ('faceid_train/(2012-05-16)(154211)/011_1_d.dat')\n",
    "inp2 = create_input_rgbd(file1)\n",
    "\n",
    "model_final.predict([inp1, inp2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
